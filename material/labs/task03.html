
		<style>
            * {
                font-family: "Open Sans";
                box-sizing :  content-box;
            }
            body {
                background-color: transparent;
            }
        </style>
		
<!doctype html>
<html>
<head>
<meta charset="utf-8"/>
<title>Notes (Layout.xbdev.net)</title>

<script src='https://f21dl.github.io/material/scripts/common.js'></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/showdown/1.8.3/showdown.js"></script>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/languages/go.min.js"></script>

<style>
* {
    -webkit-print-color-adjust: exact !important;   /* Chrome, Safari 6 15.3, Edge */
    color-adjust: exact !important;                 /* Firefox 48 */
    print-color-adjust: exact !important;           /* Firefox 97+, Safari 15.4+ */
    word-wrap: break-word;
}

table { word-break:break-all !important; }

html {
    background: #CCC;
    padding-bottom: 100vh; /* allow scrolling past end of page */
}

h1 {
    font-size: 2em !important;
}
h2 {
    font-size: 1.5em !important;
}
h3, h4, h5 {
    font-size: 1.3em !important;
}

.mdcontent {
	text-align:left;
    position:relative;
    background: #FFF;
    font-family: "Open Sans";
    line-height: 1.4;
    max-width: 700px;
    margin: auto;
    margin-top: 20px;
    padding: 100px;
    min-height: calc(100vh - 240px);
    box-shadow: 0 0 10px;
	background-color:#fff;
	color: black;
}

.mdcontent::before {    
      content: "";
      background: url("https://courses.xbdev.net/var/images/backnote.png"); 
	  background-position: right -50pt top 50pt;
	  background-repeat: no-repeat;
	  background-size: contain;	
	  background-color:#fff;
      opacity: 0.02;
      position: absolute;
      top: 0px;
      right: 0px;
      bottom: 0px;
      left: 0px;
	  z-index:0;
	  pointer-events: none;
}

@media (max-width: 568px) {
    .mdcontent {
        padding-left:20px;
        padding-right:20px;
    }
}


a {
    color: #4183C4;
    text-decoration: none;
}
a:hover {
    text-decoration: underline;
}

h1 {
    border-top: 2px solid #ddd;
    border-bottom: 2px solid #ddd;
    margin-bottom: 40px;
}

h1, h2, h3 {
    font-variant: small-caps;
    font-weight: 800;
}

li > ul {
    padding-left: 20;
}
p + ul {
    margin-top: -10;
}
li > p {
    margin-top: 0;
    margin-bottom: 10;
}

blockquote {
  border-left: 8px solid rgba(100,100,100,0.5);
  padding-left: 5px;
}

code {
    font-family: Consolas, "Lucida Console", Monaco, monospace;
    font-size: 85%;
    line-height: 150%;
    background: #f8f8f8;
    border-radius: 3px;
    border: 1px solid #e6e8db;
    padding: 1px 3px 1px 3px;
	border: 4px solid blue;
}

pre code {
	border: 4px solid green;
	display:block;
	white-space: pre-wrap;
    word-wrap: break-word;
}

hr { 
    background-color: #fff;
    border: 0;
    border-top: 2px dashed #8c8b8b;
    margin-top: 30px;
    margin-bottom: 30px;
}

table {
  border-collapse: collapse;
}

table, th, td {
  border: 1px solid black;
}
th, td {
  padding: 5px;
}
tr:hover {background-color: #f5f5f5;}

tr:nth-child(even) {background-color: #f2f2f2;}

th {
  background-color: #4C50AF;
  color: white;
}

table {
    margin-left:auto; 
    margin-right:auto;
}
</style>

<style>
.alert {
    padding: 15px;
    margin-bottom: 20px;
    border: 1px solid transparent;
    border-radius: 4px;
}

.alert-info {
    color: #31708f;
    background-color: #d9edf7;
    border-color: #bce8f1;
}
.alert-success {
    color: #3c763d;
    background-color: #dff0d8;
    border-color: #d6e9c6;
}
.alert-warning {
    color: #8a6d3b;
    background-color: #fcf8e3;
    border-color: #faebcc;
}
.alert-danger {
    color: #a94442;
    background-color: #f2dede;
    border-color: #ebccd1;
}
</style>

</head>
<body>

<div id='mdcontainer' style='text-align:center;'>
</div>
  
<br><br>

<textarea id='rawmd' style='display:none;'>
<div style='box-sizing: border-box; position:absolute;left:0px;top:0px;width:100%;height:400px;border:0px solid green;background:url(https://www.mozaweb.com/en/mozaik3D/FOL/termeszet/vulkanizmus/960.jpg) center/cover no-repeat;'></div>

<img style='position:absolute; left:20px; top: 280px;' width='200px'src='https://icon-icons.com/downloadimage.php?id=828&root=7/PNG/128/&file=history_clock_1192.png'>

<div style='height:400px;'></div>

## Data Mining and Machine Learning

In this set of practical **open-ended exercises**, you will have the opportunity to cultivate and showcase various essential skills. To demonstrate your ability to **learn independently**, **research** and choose appropriate data and tools for the problem, while encouraging **in-depth exploration beyond the provided material**. Aim of the exercises is to help you practice your capacity for rational problem identification and definition to real-world datasets and formulating well-defined solutions. You'll hone your critical analysis and solution selection skills by assessing **different approaches for tackling the problem**, justifying your choices based on their merits. Manage your time management prowess by setting intermediate milestones and adhering to deadlines throughout the exercise. Utilize relevant computer software to preprocess and analyze the data, applying appropriate techniques. These exercises will not only strengthen your technical acumen but also highlight your proficiency in addressing multifaceted aspects of the field.

> Open-ended exercises are instructional activities that lack a **single, predetermined correct answer**, fostering exploration, **critical thinking, and diverse problem-solving approaches**. These exercises prompt participants to engage deeply with a subject, encouraging them to analyze, evaluate, and synthesize information from various angles. Unlike closed-ended exercises, which have specific answers, open-ended exercises invite creativity and independent thought, often leading to a range of valid outcomes. These activities are especially useful for developing higher-order thinking skills, promoting discussion, and encouraging participants to grapple with ambiguity, uncertainty, and complex real-world scenarios. Examples of open-ended exercises include debates, case studies, research projects, and design challenges.

:::warning
These exercises should be attempted after you've reviewed the material and you want to apply the concepts to open-ended real-world examples. Record your activities/results/notes in **Jupiter Notebook**.
:::

# Attribute Selection and Model Testing Exercises


## Exercise 1: Attribute Selection Techniques
1. Load a dataset of your choice.
2. Perform a correlation analysis to identify highly correlated features.
3. Apply a filter-based attribute selection technique (e.g., information gain, chi-square) to select the most informative features.
4. Implement a wrapper-based attribute selection method (e.g., recursive feature elimination) to rank the features based on their importance.
5. Compare the results of the filter-based and wrapper-based attribute selection techniques.

<details><summary>Click to see example solution</summary>
```python
# Exercise 1: Attribute Selection Techniques

# 1. Load a dataset of your choice
import pandas as pd
dataset = pd.read_csv('dataset.csv')

# 2. Perform a correlation analysis
correlation_matrix = dataset.corr()

# 3. Apply filter-based attribute selection technique
from sklearn.feature_selection import SelectKBest, chi2

# Select top 5 features based on chi-square score
selector = SelectKBest(score_func=chi2, k=5)
selected_features = selector.fit_transform(dataset.drop('target', axis=1), dataset['target'])

# 4. Implement a wrapper-based attribute selection method
from sklearn.feature_selection import RFECV
from sklearn.ensemble import RandomForestClassifier

# Perform recursive feature elimination with cross-validation
estimator = RandomForestClassifier()
selector = RFECV(estimator, cv=5)
selector.fit(dataset.drop('target', axis=1), dataset['target'])

# Get the ranked features
ranked_features = dataset.drop('target', axis=1).columns[selector.support_]

# 5. Compare the results
print("Filter-based selected features:", dataset.drop('target', axis=1).columns[selector.get_support()])
print("Wrapper-based ranked features:", ranked_features)
```
</details>

## Exercise 2: Model Evaluation Metrics
1. Split your dataset into training and testing sets.
2. Train a classification model (e.g., logistic regression, decision tree) on the training set.
3. Use the trained model to make predictions on the testing set.
4. Calculate the following evaluation metrics:
   - Accuracy: Measure the overall correctness of the predictions.
   - Precision: Evaluate the model's ability to correctly identify positive instances.
   - Recall: Assess the model's ability to capture all positive instances.
   - F1-score: Combine precision and recall into a single metric.
   - ROC curve: Plot the true positive rate against the false positive rate.
5. Interpret and compare the evaluation metrics to assess the model's performance.

<details><summary>Click to see example solution</summary>
```python
# Exercise 2: Model Evaluation Metrics

# 1. Split your dataset into training and testing sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 2. Train a classification model
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(X_train, y_train)

# 3. Use the trained model to make predictions
y_pred = model.predict(X_test)

# 4. Calculate evaluation metrics
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
fpr, tpr, thresholds = roc_curve(y_test, y_pred)

# 5. Interpret and compare the evaluation metrics
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)
print("False Positive Rate:", fpr)
print("True Positive Rate:", tpr)
```
</details>

## Exercise 3: Cross-Validation and Model Selection
1. Implement k-fold cross-validation on your dataset (choose an appropriate value for k).
2. Train multiple classification models (e.g., SVM, random forest) using different algorithms or hyperparameters.
3. Evaluate the performance of each model using cross-validation.
4. Select the best performing model based on the average performance across all folds.
5. Apply the selected model to the testing set and calculate the evaluation metrics.

<details><summary>Click to see example solution</summary>
```python
# Exercise 3: Cross-Validation and Model Selection

# 1. Implement k-fold cross-validation
from sklearn.model_selection import StratifiedKFold
kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# 2. Train multiple classification models
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier

# Model 1: Support Vector Machine
svm_model = SVC()

# Model 2: Random Forest
rf_model = RandomForestClassifier()

# 3. Evaluate the performance of each model using cross-validation
svm_scores = []
rf_scores = []

for train_index, val_index in kf.split(X, y):
    X_train, X_val = X[train_index], X[val_index]
    y_train, y_val = y[train_index], y[val_index]
    
    # Train and evaluate SVM model
    svm_model.fit(X_train, y_train)
    svm_score = svm_model.score(X_val, y_val)
    svm_scores.append(svm_score)

    # Train and evaluate Random Forest model
    rf_model.fit(X_train, y_train)
    rf_score = rf_model.score(X_val, y_val)
    rf_scores.append(rf_score)

# 4. Select the best performing model based on the average performance across all folds
avg_svm_score = sum(svm_scores) / len(svm_scores)
avg_rf_score = sum(rf_scores) / len(rf_scores)

best_model = svm_model if avg_svm_score > avg_rf_score else rf_model

# 5. Apply the selected model to the testing set and calculate the evaluation metrics
test_score = best_model.score(X_test, y_test)
print("Best Model Test Score:", test_score)
```

**Note**: Remember to replace `X` and `y` with your actual feature and target data in the code.

</details>

## Exercise 4: Model Testing and Validation
1. Load a dataset and split it into training, validation, and testing sets.
2. Train a regression model (e.g., linear regression, random forest) on the training set.
3. Tune the hyperparameters of the model using the validation set (e.g., grid search, random search).
4. Evaluate the model's performance on the testing set using appropriate regression metrics (e.g., mean squared error, R-squared).
5. Visualize the predicted values against the actual values to assess the model's predictive ability.

<details><summary>Click to see example solution</summary>
</details>

















</textarea>

<script>

function extraMarkdown(txt)
{
	// bold words
	//txt = txt.replaceAll( /\*\*([a-zA-Z0-9 ]*)\*\* /ig, `<b>$1</b> ` );
	// italic words
	//txt = txt.replaceAll( /\*(.*?)\* /ig, `<i>$1</i> ` );

	let re = /(:::)(.*)\n((.|\n)*?)\n(:::)\n/ig;
	txt = txt.replaceAll( re, `<div markdown=1 class='alert alert-$2'>$3<div style="clear: both;"></div></div>` );

	return txt;
}


window.addEventListener('load', function() {

	// html - add attribute 'markdown=1'

	let converter = new showdown.Converter( { 
                                            tables: 'true', 
                                            disableForced4SpacesIndentedSublists: 'true', 
                                            simpleLineBreaks: 'true',
                                            strikethrough: 'true',
                                            tasklists: true,
                                            requireSpaceBeforeHeadingText: true }  );
    converter.setFlavor('github');

	let rawmd = document.getElementById('rawmd').value;

    //console.log('rawmd:', rawmd );

	let pages = rawmd.split("\n~~~");
	
	let res = '';
	pages.forEach( (p,i )=>{
		p = extraMarkdown( p );

		p = converter.makeHtml( p );		

		res += "<div id='page"+i+"' class='mdcontent'>"+p+"</div>";
	});
	
	document.getElementById('mdcontainer').innerHTML = res;


	/*
	let els = document.getElementsByClassName('mdcontent');
	els = [...els];
	els.forEach( (el)=>{
		el.innerHTML = converter.makeHtml( el.textContent );
	});
	*/

	hljs.initHighlightingOnLoad();

	
	
	let oldhash = window.location.hash;
	let newhash = oldhash.replace('#', '');
	console.log('--> old: ', oldhash, ' new:', newhash );
	
	window.location.hash = '';
	window.location.hash = newhash;
});
</script>
</body>
</html>
